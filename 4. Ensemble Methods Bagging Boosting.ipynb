{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Methods: Bagging and Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "*  For bagging, we will continue to use the same customer churn dataset that we used to build decision tree classifiers and regressors in the last practical. We will first train a random forest classifier and find a good number of base estimators by means of cross validation using: (i) oob evaluation and (ii) grid search. The performance of the classifier on customer churn prediction is then evaluated using the test set. This is followed by training of an Extra-trees classifier and comparison of the performance of the random forest and Extra-trees models. <br>\n",
    "*  For boosting, we will switch to a breast cancer dataset to train an AdaBoost classifier and a gradient boosting classifier.  We will use grid search to find optimal combinations of key hyperparameters (no. of base learners and learning rate) for both classifiers. We will also experiment with the early stopping technique in gradient boosting. We will examine and compare the performance of these classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Random forests and Extra-trees on customer churn dataset\n",
    "\n",
    "*  We will train a random forest classifier on the telecom customer churn dataset <br>\n",
    "*  The objective is to predict customer churn (true or false) based on the customers' service usage attributes in the dataset <br>\n",
    "(Some parts of the code in this section are adopted from Reference [1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data exploration and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are already familiar with the dataset from our last practical. As random forests and Extra-trees are decision tree-based models, the data preparation requirements are the same as for decision trees. Here, we will quickly go through the same steps as we did in the last practical to prepare the dataset. <br>\n",
    "* Import the customer churn data <br>\n",
    "* Remove the columns that are unlikely to be useful for prediction <br>\n",
    "* Encode nominal data ('yes'/'no') to boolean values <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Orange_Telecom_Churn_Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the attribues `state`, `phone_number` and `area_code` as they are unlikely to be useful predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-09T22:20:28.468823Z",
     "start_time": "2017-04-09T18:20:28.458898-04:00"
    }
   },
   "outputs": [],
   "source": [
    "data.drop(['state', 'phone_number', 'area_code'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode `intl_plan` and `voice_mail_plan` as True/False as tree-based models in Scikit-Learn are unable to handle categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['intl_plan', 'voice_mail_plan']:\n",
    "    data[col] = data[col].replace('yes',True).replace('no',False).astype(np.bool)\n",
    "      \n",
    "data[['intl_plan', 'voice_mail_plan']].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the dataset is skewed (about 86% are non-churned customers), we will apply stratified split to divide the dataset into the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-09T22:20:34.008973Z",
     "start_time": "2017-04-09T18:20:33.561995-04:00"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Separate feature columns and the target column\n",
    "feature_cols = [x for x in data.columns if x != 'churned']\n",
    "\n",
    "# Split the data into two parts with 1500 points in the test data\n",
    "\n",
    "# This creates a generator\n",
    "strat_shuff_split = StratifiedShuffleSplit(n_splits=1, test_size=1500, random_state=42)\n",
    "\n",
    "# Get the index values from the generator\n",
    "train_idx, test_idx = next(strat_shuff_split.split(data[feature_cols], data['churned']))\n",
    "\n",
    "# Create the data sets\n",
    "X_train = data.loc[train_idx, feature_cols]\n",
    "y_train = data.loc[train_idx, 'churned']\n",
    "\n",
    "X_test = data.loc[test_idx, feature_cols]\n",
    "y_test = data.loc[test_idx, 'churned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation is done <br>\n",
    "Now, build random forests and Extra-trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-09T22:22:27.940967Z",
     "start_time": "2017-04-09T18:22:27.934979-04:00"
    }
   },
   "outputs": [],
   "source": [
    "# Suppress warnings about too few trees from the early models\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def measure_error(y_true, y_pred, label):\n",
    "    return pd.Series({'accuracy':accuracy_score(y_true, y_pred),\n",
    "                      'precision': precision_score(y_true, y_pred),\n",
    "                      'recall': recall_score(y_true, y_pred),\n",
    "                      'f1': f1_score(y_true, y_pred)},\n",
    "                      name=label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Random forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fit random forest models with a range of tree numbers and evaluate the out-of-bag error for each of these models <br>\n",
    "* Plot the resulting oob errors as a function of the number of trees <br>\n",
    "* Since the only thing changing is the number of trees, the `warm_start` flag can be used so that the model just adds more trees to the existing model each time <br>\n",
    "* Use the `set_params` method to update the number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the random forest estimator\n",
    "# Note that the number of trees is not setup here\n",
    "\n",
    "rf_clf = RandomForestClassifier(oob_score=True, \n",
    "                                random_state=42, \n",
    "                                warm_start=True,\n",
    "                                n_jobs=-1)\n",
    "\n",
    "oob_list = list()\n",
    "\n",
    "# Iterate through a range of numbers of trees\n",
    "\n",
    "for n_trees in [10, 50, 100, 500, 600, 800, 1000, 1100, 1200, 1300, 1400, 1500]:\n",
    "    \n",
    "    # Use this to set the number of trees\n",
    "    rf_clf.set_params(n_estimators=n_trees)\n",
    "\n",
    "    # Fit the model\n",
    "    rf_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Get the oob error\n",
    "    oob_error = 1 - rf_clf.oob_score_\n",
    "    \n",
    "    # Store it\n",
    "    oob_list.append(pd.Series({'n_trees': n_trees, 'oob': oob_error}))\n",
    "\n",
    "rf_oob = pd.concat(oob_list, axis=1).T.set_index('n_trees')\n",
    "\n",
    "rf_oob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error appears to have stabilized from around 1100 trees <br>\n",
    "Plot the graph for easy visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "sns.set_palette('dark')\n",
    "sns.set_style('white')\n",
    "\n",
    "ax = rf_oob.plot(legend=False, marker='o')\n",
    "ax.set(ylabel='out-of-bag error');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Extra-trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Repeat Section 1.2 using Extremely Randomized Trees (`ExtraTreesClassifier`) <br>\n",
    "* Note that the `bootstrap` parameter will have to be set to `True` for this model, to indicate that we want to use bagging <br>\n",
    "* Compare the out-of-bag errors for the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Initialize the Extra-trees estimator\n",
    "# Note that the number of trees is not setup here\n",
    "\n",
    "et_clf = ExtraTreesClassifier(oob_score=True, \n",
    "                              random_state=42, \n",
    "                              warm_start=True,\n",
    "                              bootstrap=True,\n",
    "                              n_jobs=-1)\n",
    "\n",
    "oob_list = list()\n",
    "\n",
    "# Iterate through a range of numbers of trees\n",
    "for n_trees in [10, 50, 100, 500, 600, 800, 1000, 1100, 1200, 1300, 1400, 1500]:\n",
    "       \n",
    "    # Use this to set the number of trees\n",
    "    et_clf.set_params(n_estimators=n_trees)\n",
    "    et_clf.fit(X_train, y_train)\n",
    "\n",
    "    # oob error\n",
    "    oob_error = 1 - et_clf.oob_score_\n",
    "    oob_list.append(pd.Series({'n_trees': n_trees, 'oob': oob_error}))\n",
    "\n",
    "et_oob = pd.concat(oob_list, axis=1).T.set_index('n_trees')\n",
    "\n",
    "et_oob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the two dataframes into a single one for easier plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oob_df = pd.concat([rf_oob.rename(columns={'oob':'RandomForest'}),\n",
    "                    et_oob.rename(columns={'oob':'ExtraTrees'})], axis=1)\n",
    "\n",
    "oob_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "sns.set_palette('dark')\n",
    "sns.set_style('white')\n",
    "\n",
    "ax = oob_df.plot(marker='o')\n",
    "ax.set(ylabel='out-of-bag error');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest model performs consistently better than the Extra-trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Evaluation of random forest classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the random forest model <br>\n",
    "First, instantiate a random forest with 1100 base estimators that gives the lowest oob error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest with 1100 estimators\n",
    "\n",
    "rf_clf = rf_clf.set_params(n_estimators=1100, warm_start=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in decision trees, we can plot the feature importances <br>\n",
    "They are not exactly, but more or less, the same as those obtained from the decision trees in the last practical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.Series(rf_clf.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "ax = feature_imp.plot(kind='bar')\n",
    "ax.set(ylabel='Relative Importance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the performance of the random forest model using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-09T22:23:23.367818Z",
     "start_time": "2017-04-09T18:23:23.150988-04:00"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_pred = cross_val_predict(rf_clf, X_train, y_train, cv=3, method=\"predict\")\n",
    "y_train_pred_prob = cross_val_predict(rf_clf, X_train, y_train, cv=3, method=\"predict_proba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the error metrics on cross-validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error = pd.concat([measure_error(y_train, y_train_pred, 'train')],\n",
    "                         axis=1)\n",
    "\n",
    "train_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "sns.set_context('talk')\n",
    "ax = sns.heatmap(cm, annot=True, fmt='d')\n",
    "labels = ['False', 'True']\n",
    "ax.set_xticklabels(labels);\n",
    "ax.set_yticklabels(labels);\n",
    "ax.set_ylabel('Actual');\n",
    "ax.set_xlabel('Predicted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would be the performance of this classifier on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error = pd.concat([measure_error(y_test, y_test_pred, 'test')],\n",
    "                       axis=1)\n",
    "\n",
    "test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are comparable with the test results of optimized decision tree models built in the last practical, but recall for positive class (churned customers) is still not great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the last practical, we can take a look at the predicted probability of training instances versus their true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.replace(True, 1).replace(False, 0).astype(np.int64)\n",
    "\n",
    "y_train_scores = y_train_pred_prob[:, 1]\n",
    "\n",
    "train_predict = pd.DataFrame({'actual': y_train.values,\n",
    "                              'predict': y_train_scores})\n",
    "\n",
    "train_predict.plot.scatter(x='predict', y='actual', s=list(range(2,500)), alpha=0.05, figsize=(10,6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution looks better than what we could get from the decision tree models in the last practical <br>\n",
    "It seems like there is a chance to achieve a better balance of precision and recall for both classes by adjusting the decision threshold in terms of the prediction probability as we did with the decision trees in the last practical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the precision/recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train, y_train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_curve(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
    "    plt.xlabel(\"Threshold\", fontsize=16)\n",
    "    plt.legend(loc=\"upper right\", fontsize=16)\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plot_precision_recall_curve(precisions, recalls, thresholds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try decision threshold at 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = (y_train_scores > 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error = pd.concat([measure_error(y_train, y_train_pred, 'train')],\n",
    "                         axis=1)\n",
    "\n",
    "train_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks promising <br>\n",
    "Let's predict on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_prob = rf_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_scores = y_test_pred_prob[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the same threshold for predicting the test instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = (y_test_scores > 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error = pd.concat([measure_error(y_test, y_test_pred, 'test')],\n",
    "                        axis=1)\n",
    "\n",
    "test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This set of balanced results is a huge improvement from what we could get from the decision tree models of the last practical, even without compensating for skewed class distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Optimized random forest classifier based on grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, instead of using oob evaluation, we can also determine the optimal number of trees using grid search (a technique that we've learned in the last practical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_estimators': [500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500]}\n",
    "\n",
    "gr_rf_clf = GridSearchCV(RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "                         param_grid=param_grid,\n",
    "                         scoring='accuracy',\n",
    "                         n_jobs=-1)\n",
    "\n",
    "gr_rf_clf = gr_rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_rf_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of base estimators is not far from what we got from the oob evaluation (Section 1.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = gr_rf_clf.predict(X_train)\n",
    "y_test_pred = gr_rf_clf.predict(X_test)\n",
    "# y_test_pred_prob = gr_rf_clf.predict_proba(X_test)\n",
    "\n",
    "train_test_error = pd.concat([measure_error(y_train, y_train_pred, 'train'),\n",
    "                              measure_error(y_test, y_test_pred, 'test')],\n",
    "                              axis=1)\n",
    "\n",
    "train_test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "sns.set_context('talk')\n",
    "ax = sns.heatmap(cm, annot=True, fmt='d')\n",
    "labels = ['False', 'True']\n",
    "ax.set_xticklabels(labels);\n",
    "ax.set_yticklabels(labels);\n",
    "ax.set_ylabel('Actual');\n",
    "ax.set_xlabel('Predicted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is similar to the model obtained through oob evaluation (before adjusting the deceision threshold) in Section 1.4, which is expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have experimented with the `class_weight` method to deal with the imbalanced dataset when constructing the decision tree model <br>\n",
    "You may try a similar technique in random forests by setting the hyperparameter `class_weight='balanced_subsample'` when creating the `RandomForestClassifier()` instance <br>\n",
    "Interest learners may refer to this article: https://machinelearningmastery.com/bagging-and-random-forest-for-imbalanced-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Boosting with AdaBoost and gradient boosting\n",
    "* In this part of the practical, we will be using the Wisconsin Diagnostic breast cancer dataset, which is one of the datasets that we can load from Scikit-Learn <br>\n",
    "* The dataset consists of 569 training samples and 30 features <br>\n",
    "* The features are tumor attributes captured from medical images, and the target attribute to be predicted is whether the tumor is malignant or benign <br>\n",
    "* We will learn to build an AdaBoost classifier and a gradient boosting classifier with this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data exploration and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we need to understand more about the dataset and take the necessary steps to prepare the data for our machine learning task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "bc = load_breast_cancer() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most datasets available from Scikit-Learn have a `DESCR` property that gives a detailed description about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.DESCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the other properties available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the features in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bc.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the target labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored with the `data` key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target column is stored with the `target` key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to combine the data and target into a data frame, and name the target column as 'malignant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.c_[bc.data, bc.target]\n",
    "column_names = np.append(bc.feature_names, ['malignant'])\n",
    "data = pd.DataFrame(data, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take note that the target labels are already numerically coded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['malignant'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['malignant'].value_counts()\n",
    "data['malignant'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the `DESCR` (Class Distribution: 212 - Malignant, 357 - Benign), we know that 'Malignant' is currently coded as 0.0, and 'Benign' as 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to recode 'Malignant' to True (positive class) and 'Benign' to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['malignant'] = (data['malignant'] == 0.0).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['malignant'].value_counts()\n",
    "data['malignant'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As both AdaBoost and gradient boosting are tree-based models, data scaling is not necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as the dataset is slightly skewed, we should use the stratified train/test split method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "feature_cols = [x for x in data.columns if x != 'malignant']\n",
    "\n",
    "# Create the generator\n",
    "strat_shuff_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Get the index values from the generator\n",
    "train_idx, test_idx = next(strat_shuff_split.split(data[feature_cols], data['malignant']))\n",
    "\n",
    "# Create the training and test sets\n",
    "X_train = data.loc[train_idx, feature_cols]\n",
    "y_train = data.loc[train_idx, 'malignant']\n",
    "\n",
    "X_test = data.loc[test_idx, feature_cols]\n",
    "y_test = data.loc[test_idx, 'malignant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation is complete <br>\n",
    "Now build the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_error(y_true, y_pred, label):\n",
    "    return pd.Series({'accuracy': accuracy_score(y_true, y_pred),\n",
    "                      'precision': precision_score(y_true, y_pred),\n",
    "                      'recall': recall_score(y_true, y_pred),\n",
    "                      'f1': f1_score(y_true, y_pred)},\n",
    "                      name=label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 AdaBoost classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an AdaBoost classifier and fit it using grid search <br> \n",
    "Try a range of number of estimators and learning rates <br>\n",
    "\n",
    "NOTE: Setting `max_features=4` in the decision tree base estimators will increase the convergence rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1, max_features=4, random_state=42),\n",
    "                             random_state=42)\n",
    "\n",
    "param_grid = {'n_estimators': [50, 100, 150, 200, 250, 300, 350, 400],\n",
    "              'learning_rate': [0.3, 0.1, 0.01]}\n",
    "\n",
    "gr_ada_clf = GridSearchCV(ada_clf,\n",
    "                          param_grid=param_grid, \n",
    "                          scoring='accuracy',\n",
    "                          n_jobs=-1)\n",
    "\n",
    "gr_ada_clf = gr_ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model found by the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_ada_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_ada_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = gr_ada_clf.predict(X_train)\n",
    "y_test_pred = gr_ada_clf.predict(X_test)\n",
    "\n",
    "train_test_full_error = pd.concat([measure_error(y_train, y_train_pred, 'train'),\n",
    "                                   measure_error(y_test, y_test_pred, 'test')],\n",
    "                                   axis=1)\n",
    "print(train_test_full_error)\n",
    "print()\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print()\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "sns.set_context('talk')\n",
    "ax = sns.heatmap(cm, annot=True, fmt='d')\n",
    "labels = ['False', 'True']\n",
    "ax.set_xticklabels(labels);\n",
    "ax.set_yticklabels(labels);\n",
    "ax.set_ylabel('Actual');\n",
    "ax.set_xlabel('Predicted');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Gradient boosting classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creare a gradient boosting classifier and fit it with grid search <br>\n",
    "In grid search, we try to vary the two key hyperparameters, `n_estimators` and `learning_rate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_estimators': [50, 100, 200, 300, 400], 'learning_rate': [0.1, 0.01]}\n",
    "\n",
    "gr_gb_clf = GridSearchCV(GradientBoostingClassifier(max_features=4, random_state=42),\n",
    "                      param_grid=param_grid,\n",
    "                      scoring='accuracy',\n",
    "                      n_jobs=-1)\n",
    "\n",
    "gr_gb_clf = gr_gb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_gb_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_gb_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = gr_gb_clf.predict(X_train)\n",
    "y_test_pred = gr_gb_clf.predict(X_test)\n",
    "\n",
    "train_test_full_error = pd.concat([measure_error(y_train, y_train_pred, 'train'),\n",
    "                                   measure_error(y_test, y_test_pred, 'test')],\n",
    "                                   axis=1)\n",
    "print(train_test_full_error)\n",
    "print()\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print()\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "sns.set_context('talk')\n",
    "ax = sns.heatmap(cm, annot=True, fmt='d')\n",
    "labels = ['False', 'True']\n",
    "ax.set_xticklabels(labels);\n",
    "ax.set_yticklabels(labels);\n",
    "ax.set_ylabel('Actual');\n",
    "ax.set_xlabel('Predicted');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another technique for searching optimal results is early stopping <br>\n",
    "We set the hyperparameter `n_iter_no_change` to enable early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier(n_estimators=400, learning_rate=0.01, max_features=4, \n",
    "                                    n_iter_no_change=50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual number of base learners trained (the higher number of base learners is due to the lower learning rate set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf.n_estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = gb_clf.predict(X_train)\n",
    "y_test_pred = gb_clf.predict(X_test)\n",
    "\n",
    "train_test_full_error = pd.concat([measure_error(y_train, y_train_pred, 'train'),\n",
    "                                   measure_error(y_test, y_test_pred, 'test')],\n",
    "                                   axis=1)\n",
    "print(train_test_full_error)\n",
    "print()\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print()\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "sns.set_context('talk')\n",
    "ax = sns.heatmap(cm, annot=True, fmt='d')\n",
    "labels = ['False', 'True']\n",
    "ax.set_xticklabels(labels);\n",
    "ax.set_yticklabels(labels);\n",
    "ax.set_ylabel('Actual');\n",
    "ax.set_xlabel('Predicted');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the accuracy of higher than 97% is nice, we would hope that the false negative cases (now 3) could be lower. What could we possibly investigate further? <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "[1] Intel AI Academy, Machine Learning 501. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
